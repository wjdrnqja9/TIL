{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjdrnqja9/TIL/blob/main/machine_learning/04_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93yQqP6ouezf"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6sLWyB6ugPe"
      },
      "source": [
        "## PCA(Principal Component Analysis): 주성분분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXzJhaqovTOX"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE0tB_6YvTOX"
      },
      "source": [
        "#### 기본 설명\n",
        "\n",
        "- PCA란 입력 데이터들의 공분산 행렬(covariance matrix)에 대한 고유값 분해\n",
        "- 기존 데이터의 분포를 최대한 보존하면서 고차원 공간의 데이터들을 저차원 공간으로 변환하는 차원축소기법 중 하나이다.\n",
        "- 다시말해, 데이터의 분산(variance)을 최대한 보존하는 축(서로 직교하는 새 기저)을 찾아 고차원 공간의 데이터를 선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다.\n",
        "- PCA는 기존의 변수를 조합하여 서로 연관성이 없는 새로운 변수, 즉 주성분(principal component)을 만들어낸다.\n",
        "- 예를 들어, PC1, PC2, PC3이 기존 데이터의 분포를 잘 나타내는 순서라고 하자. 이 때, PC1, PC2, PC3이 기존 데이터의 분포를 약 90%(예시)이상 보존한다면 나머지 10%의 데이터 분포(또는 정보)는 잃어버려도 큰 문제가 없다라고 판단한다.\n",
        "- 자세한 증명을 알고싶다면 [여기](https://tyami.github.io/machine%20learning/PCA/)를 참고!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUrKqWKovTOY"
      },
      "source": [
        "#### 사용예시\n",
        "\n",
        "- 얼굴인식\n",
        "- 정규화\n",
        "- 노이즈를 없애는 도구\n",
        "- 다중공선성이 존재할 때 상관도가 높은 변수를 축소\n",
        "- 연관성 높은 변수를 제거하여 연산속도 및 결과치 개선\n",
        "- 다양한 센서데이터를 주성분분석하여 시계열로 분포나 추세를 분석하고 고장징후탐지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzk50ceSvTOY"
      },
      "source": [
        "#### scikit-learn PCA 예시\n",
        "\n",
        "- components_: 주성분 축\n",
        "- n_components_: 주성분의 수\n",
        "- mean_: 각 성분의 평균\n",
        "- explained_variance_ratio_: 각 성분의 분산 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UYFvL7AvTOY"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "\n",
        "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'] # 컬럼 명\n",
        "irisDF = pd.DataFrame(iris.data, columns = columns) # 데이터프레임 생성\n",
        "irisDF['target'] = iris.target # 타깃변수 생성\n",
        "\n",
        "irisDF.head(3) # 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGSnT0NlvTOZ"
      },
      "outputs": [],
      "source": [
        "# setosa는 세모, versicolor는 네모, virginica는 동그라미로 표현\n",
        "markers=['^', 's', 'o']\n",
        "\n",
        "# setosa의 target 값은 0, versicolor는 1, virginica는 2. 각 target별로 다른 모양으로 산점도로 표시\n",
        "for i, marker in enumerate(markers):\n",
        "    x_axis_data = irisDF[irisDF['target'] == i]['sepal_length']\n",
        "    y_axis_data = irisDF[irisDF['target'] == i]['sepal_width']\n",
        "    plt.scatter(x_axis_data, y_axis_data, marker=marker, label=iris.target_names[i])\n",
        "    \n",
        "plt.legend()\n",
        "plt.xlabel('sepal length') # x축\n",
        "plt.ylabel('sepal width') # y축\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtvZuX8svTOa"
      },
      "source": [
        "- PCA를 적용하기전 scaling을 진행하는 이유는 무엇일까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAW16EjDvTOa"
      },
      "outputs": [],
      "source": [
        "# 사이킷런의 StandardScaler를 이용해 평균이 0, 분산이 1인 표준 정규 분포로 근사\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Target 값을 제외한 모든 속성 값을 StandardScaler를 이용해 표준 정규 분포를 가지는 값들로 변환\n",
        "iris_scaled = StandardScaler().fit_transform(irisDF.drop('target', axis=1))\n",
        "iris_scaled[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iziVQmNtvTOb"
      },
      "source": [
        "- 4개의 feature를 2개로 압축하여 데이터 분포를 2차원(PCA 속성)으로 시각화하기!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mfB8khBvTOb"
      },
      "outputs": [],
      "source": [
        "# 사이킷런은 PCA 변환을 위해 PCA 클래스를 제공\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA 클래스는 n_components라는 PCA로 변환할 차원의 수를 의미하는 생성 파라미터를 인자로 받음\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "#fit()과 transform()을 호출해 PCA 변환 데이터 반환\n",
        "pca.fit(iris_scaled)\n",
        "iris_pca = pca.transform(iris_scaled)\n",
        "print(iris_pca.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DchevXZpvTOb"
      },
      "outputs": [],
      "source": [
        "# numpy결과값을 pandas dataframe으로 변경\n",
        "# PCA 변환된 데이터의 칼럼 명을 각각 pca_component_1, pca_component_2로 명명\n",
        "pca_columns = ['pca_component_1', 'pca_component_2']\n",
        "irisDF_pca = pd.DataFrame(iris_pca, columns = pca_columns)\n",
        "irisDF_pca['target'] = iris.target\n",
        "irisDF_pca.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYsTGDBxvTOb"
      },
      "outputs": [],
      "source": [
        "#setosa는 세모, versicolor는 네모, virginica는 동그라미로 표현\n",
        "markers=['^', 's', 'o']\n",
        "\n",
        "#setosa의 target 값은 0, versicolor는 1, virginica는 2. 각 target별로 다른 모양으로 산점도로 표시\n",
        "for i, marker in enumerate(markers):\n",
        "    x_axis_data = irisDF_pca[irisDF['target'] == i]['pca_component_1']\n",
        "    y_axis_data = irisDF_pca[irisDF['target'] == i]['pca_component_2']\n",
        "    plt.scatter(x_axis_data, y_axis_data, marker=marker, label=iris.target_names[i])\n",
        "    \n",
        "plt.legend()\n",
        "plt.xlabel('pca_component_1')\n",
        "plt.ylabel('pca_component_2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fru0VpHJvTOc"
      },
      "source": [
        "- PCA란 데이터의 변동성(분산)을 가장 잘 설명할 수 있는 축을 찾아 데이터 차원을 축소하는 기법\n",
        "- PCA Component별 원본 데이터의 변동성(분산)을 얼마나 반영하고 있는지 알아보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5ezuuCXvTOc"
      },
      "outputs": [],
      "source": [
        "# explained_variance_ratio_ 속성은 전체 변동성에서 개별 PCA 컴포넌트별로 차이하는 변동성의 비율을 제공\n",
        "print(pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_3iz-a3vTOc"
      },
      "source": [
        "- 첫번째 pca_component가 전체 데이터의 약 73%를 차지하고, 두번째가 약 23%를 차지하고 있다. \n",
        "- 2개의 pca_component만으로 약 95%를 설명할 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcWm-il9vTOc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "04-pca.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}